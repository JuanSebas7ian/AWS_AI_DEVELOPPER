{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar las bibliotecas necesarias\n",
    "import boto3  # Para interactuar con servicios de AWS\n",
    "import json   # Para manejar datos JSON\n",
    "\n",
    "# Inicializar el cliente de Bedrock Runtime\n",
    "# Esto permite invocar modelos de IA generativa en AWS Bedrock\n",
    "bedrock_runtime = boto3.client('bedrock-runtime')\n",
    "\n",
    "# Definir el ID del modelo Titan de Amazon\n",
    "# Este es el modelo específico que usaremos para generar texto\n",
    "model_id_titan = \"amazon.titan-text-premier-v1:0\"\n",
    "\n",
    "# Función de ejemplo para generar texto\n",
    "def generate_text():\n",
    "    \"\"\"\n",
    "    Genera texto utilizando el modelo Amazon Titan a través de AWS Bedrock.\n",
    "    \n",
    "    Esta función crea un payload con texto de entrada y configuración de generación,\n",
    "    invoca el modelo y devuelve el texto generado.\n",
    "    \n",
    "    Parámetros:\n",
    "        Ninguno (usa valores hardcodeados para el ejemplo)\n",
    "    \n",
    "    Retorna:\n",
    "        dict: La respuesta del modelo, que incluye el texto generado.\n",
    "    \n",
    "    Ejemplo:\n",
    "        result = generate_text()\n",
    "        print(result)\n",
    "    \"\"\"\n",
    "    # Crear el payload con el texto de entrada y configuración\n",
    "    payload = {\n",
    "        \"inputText\": \"Explain quantum computing in simple terms.\",  # Texto de entrada para el modelo\n",
    "        \"textGenerationConfig\": {\n",
    "            \"maxTokenCount\": 500,  # Máximo número de tokens en la respuesta\n",
    "            \"temperature\": 0.5,     # Controla la creatividad (0.0 = determinista, 1.0 = muy creativo)\n",
    "            \"topP\": 0.9             # Controla la diversidad del texto generado\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Invocar el modelo usando el cliente de Bedrock\n",
    "    # Se pasa el ID del modelo y el payload serializado como JSON\n",
    "    response = bedrock_runtime.invoke_model(\n",
    "        modelId=model_id_titan,\n",
    "        body=json.dumps(payload)  # Convertir el payload a string JSON\n",
    "    )\n",
    "    \n",
    "    # Procesar la respuesta: leer el cuerpo y convertir de JSON a diccionario Python\n",
    "    return json.loads(response['body'].read())\n",
    "\n",
    "# Ejemplo de uso de la función\n",
    "# Llamar a la función y almacenar el resultado\n",
    "result = generate_text()\n",
    "print(result)  # Imprimir el resultado generado\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

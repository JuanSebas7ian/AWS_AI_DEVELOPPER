{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d24c4926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'toolUse': {'toolUseId': 'tooluse_Z-TPF5AuQBuNpMkvIkcoBQ', 'name': 'calculateNumbers', 'input': {'num1': 5, 'operation': 'power', 'num2': 100}}}\n",
      "→ Assistant triggered tool: calculateNumbers with input: {'num1': 5, 'operation': 'power', 'num2': 100}\n",
      "← Lambda Function output: {'result': 7.888609052210118e+69}\n",
      "\n",
      "=== Final Assistant Response ===\n",
      "The result of raising 5 to the power of 100 is an extremely large number, expressed as \\(7.888609052210118 \\times 10^{69}\\). This is a very large value, highlighting the rapid growth of exponential functions. If you need any further clarification or have another request, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "# Setup Bedrock and Lambda\n",
    "import boto3\n",
    "import json\n",
    "\n",
    "bedrock = boto3.client(service_name='bedrock-runtime')\n",
    "lambda_client = boto3.client(\"lambda\")\n",
    "MODEL_ID = \"amazon.nova-micro-v1:0\"\n",
    "\n",
    "# Define the calculation tool\n",
    "math_tool = {\n",
    "    \"toolSpec\": {\n",
    "        \"name\": \"calculateNumbers\",\n",
    "        \"description\": \"Performs basic arithmetic operations\",\n",
    "        \"inputSchema\": {\n",
    "            \"json\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"operation\": {\"type\": \"string\"},\n",
    "                    \"num1\": {\"type\": \"number\"},\n",
    "                    \"num2\": {\"type\": \"number\"}\n",
    "                },\n",
    "                \"required\": [\"operation\", \"num1\", \"num2\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Function to trigger the Lambda calculation service\n",
    "def execute_calculation(input_data):\n",
    "    response = lambda_client.invoke(\n",
    "        FunctionName=\"math-function\",  \n",
    "        InvocationType=\"RequestResponse\",\n",
    "        Payload=json.dumps(input_data)\n",
    "    )\n",
    "    response_payload = response[\"Payload\"].read()\n",
    "    calculation_result = json.loads(response_payload)\n",
    "    response_body = calculation_result.get(\"body\", \"{}\")\n",
    "    return json.loads(response_body) if isinstance(response_body, str) else response_body\n",
    "\n",
    "# User's initial message\n",
    "user_input = {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": [{\"text\": \"Please power 5 from 100\"}]\n",
    "}\n",
    "\n",
    "# Define system instructions\n",
    "system_instructions = [\n",
    "    {\"text\": \"\"\"\n",
    "    You are a virtual assistant capable of performing basic arithmetic operations: add, subtract, multiply, and divide.\n",
    "    If the user doesn't specify an operation, ask them for more details.\n",
    "    \"\"\"}\n",
    "]\n",
    "\n",
    "# First interaction with the model\n",
    "first_interaction = bedrock.converse(\n",
    "    modelId=MODEL_ID,\n",
    "    system=system_instructions,\n",
    "    messages=[user_input],\n",
    "    toolConfig={\n",
    "        \"tools\": [math_tool],\n",
    "        \"toolChoice\": {\"auto\": {}}\n",
    "    },\n",
    "    inferenceConfig={\"temperature\": 0.7}\n",
    ")\n",
    "\n",
    "# Process the assistant's response to check if tool is required\n",
    "assistant_reply = first_interaction[\"output\"][\"message\"]\n",
    "message_parts = assistant_reply[\"content\"]\n",
    "tool_request_block = next((part for part in message_parts if \"toolUse\" in part), None)\n",
    "\n",
    "if not tool_request_block:\n",
    "    print(\"=== Assistant's Direct Response ===\")\n",
    "    print(message_parts[0][\"text\"])\n",
    "else:\n",
    "    tool_request = tool_request_block[\"toolUse\"]\n",
    "    tool_input_data = tool_request[\"input\"]\n",
    "    tool_id = tool_request[\"toolUseId\"]\n",
    "    print(tool_request_block)\n",
    "    print(f\"→ Assistant triggered tool: calculateNumbers with input: {tool_input_data}\")\n",
    "\n",
    "    # Execute the requested tool\n",
    "    tool_result = execute_calculation(tool_input_data)\n",
    "    print(f\"← Lambda Function output: {tool_result}\")\n",
    "\n",
    "    # Create a response based on the tool's output\n",
    "    try:\n",
    "        result_summary = f\"The outcome of the calculation is {tool_result['result']}.\"\n",
    "    except Exception as e:\n",
    "        result_summary = f\"Oops! There was an error with the calculation. ({str(e)})\"\n",
    "\n",
    "    # Generate tool result message\n",
    "    tool_response_msg = {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"toolResult\": {\n",
    "                    \"toolUseId\": tool_id,\n",
    "                    \"content\": [{\"text\": result_summary}]\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    # Send tool result back to the model\n",
    "    final_output = bedrock.converse(\n",
    "        modelId=MODEL_ID,\n",
    "        messages=[user_input, assistant_reply, tool_response_msg],\n",
    "        toolConfig={  \n",
    "            \"tools\": [math_tool],\n",
    "            \"toolChoice\": {\"auto\": {}}\n",
    "        },\n",
    "        inferenceConfig={\"temperature\": 0.7}\n",
    "    )\n",
    "\n",
    "    # Display the final response from the assistant\n",
    "    final_message = final_output[\"output\"][\"message\"][\"content\"][0][\"text\"]\n",
    "    print(\"\\n=== Final Assistant Response ===\")\n",
    "    print(final_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e523d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
